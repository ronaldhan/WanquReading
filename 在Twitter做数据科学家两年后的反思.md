# 在Twitter做数据科学家两年后的反思

标签（空格分隔）： Twitter 数据科学家

---

[TOC]

### 动机
作者在 twitter 工作两年了，从事的职位是数据科学家(Data Science)，两年间 twitter 的数据科学工作也发生了不少变化，总结一下主要是几点：

* 机器学习扮演越来越重要的角色，许多 twitter 的产品被改造成为机器学习驱动
* 进行数据科学的工具更加智能化。从`Pig`和其它流水线转移到`Scalding`，这是一个使用 Scala 编写的 DSL，用于在更高层次进行Map/Reduce任务
* 组织架构上，数据科学团队转向了与产品和工程团队更加密切合作的嵌入式模式

关于如何成为一个数据科学家有许多争论，有些过分强调工具和技术，而我认为要让人们知道在实际中一个数据科学家是如何工作的，方便其他人学习和借鉴。同时，也是对自己过去工作的一个反思。这两条是作者的写作动机。

### A类数据科学家和B类数据科学家
先说一种错误的认识。在没去 twitter 工作之前，我心目中数据科学家就像是独角兽一样的，这个人需要精通多门学科的知识，从数学/统计，计算机科学/机器学习/算法，到数据可视化。还需要有技术写作和沟通能力，需要监管项目的进度，推进项目执行。另外，还要成为数据驱动文化的传教士，如此种种。
刚开始工作几个月后我算是明白了，这样的独角兽确实是存在的，但是对于像我这样的新手，距离这样的目标还真是有点远。照理说，公司里面一切跟数据有关的事情和数据科学都有关系，但是一个新手还真是不容易找到合适的位置在哪里。
随着工作的推进，我逐渐意识到可以使用一种二分法把数据科学家进行比较精确地划分，但是一直没找到合适的概括，直到在`Quora`上看到[Michael Hochster](http://www.quora.com/Michael-Hochster)的概括才恍然大悟。他是这么讲的：

    A类数据科学家：A指的是分析(Analysis)，主要关注如何合理地使用数据，是从统计学的角度来使用数据。一般而言，这类人比较接近统计学家，但是更加关注一些统计学家不关注的内容：数据清洗，处理大数据集的方法，数据可视化，领域知识，对数据的解读等等。
    
    B类数据科学家：B指的是构建(Building)，这类人和A类数据科学家可能都有统计知识的北京，但这类人更像是更好的coder或受过良好训练的软件工程师。B类数据科学家更关注如何把数据应用在生产环境中，构建能够与用户产生交互的模型，通常服务的领域是推荐(产品，可能了解的人，广告，电影，搜索结果)。
    
他的这种划分方法非常简明，也非常有用，真心希望自己能够早点直到这个。作为数据科学家，牢记这种划分对于职业决策也非常有帮助。
对于作者而言，他是数学，运筹学和统计学背景，所以把自己定位在A类数据科学家上，但同时对B类数据科学家也非常有兴趣，希望能够更多地参加到工程实践中。

### 创业公司，快速发展的创业公司或者期望快速扩大规模的公司中的数据科学家
找工作时候通常都会面临的一个选择题是：大公司还是创业小公司。大家已经有很多讨论了，但是对于数据科学家，并没有一个明确的结论说这个职位在不同阶段的公司是个什么职责。

不同阶段的公司在产生数据的3Vs(velocity, variety, 和volume)方面差异很大。刚创业的公司更侧重在找到符合市场的产品，它的数据量可能不需要使用 Hadoop，一个快速成长的创业公司可能虽然也生成大量的数据，但可能使用 PostgreSQL 或 Vertica就够了。但是，一个像 twitter 这样的公司，没有 Hadoop 和 MR 框架是完全处理不了数据的。

我在 twitter 学到的一个经验是，数据科学家从数据中得到有价值结果的量与这个公司数据平台的成熟程度成正比。了解自己更期望做A类还是B类数据科学家，并评估一下公司的数据基础设施能够满足你发挥所需要的条件，是确定公司与个人是否相互匹配的首要大事。

* 对于初创公司：最重要的事是做好日志，设计 ETL 流程，设计合适的数据存储模式。目标在于建立数据分析的基础设施，而不是分析数据。
* 对于已经处于高速发展期的初创公司：这类公司处于发展期，数据也在快速增长，数据基础设施已经搭建好了，很自然的会将目光转移到如何挖掘数据上。除非公司是将数据科学家用来分析不同策略的差异，否则很可能要被派去做定义 KPI，用户增长，或者寻找增长机会的工作。
* 已经颇具规模的公司：公司规模增大， 数据规模也会随着增大。这时候公司需要使用数据分析来维持自己的竞争优势。比如，搜索结果需要更精准，推荐需要更相关，物流和运营需要更加高效。在这种情况下，机器学习专家，运筹学和经验丰富的设计会发挥更大的作用。

### 我自己的经历
最初到 twitter 是加入到 Growth 团队，实际上，我花了好几个月才搞清楚如何在 Growth 方向展开数据科学。依据我和产品团队的合作经验，我的职责大体包含四块：

* 深入的产品分析(Product Insights)
* 数据流水线(Data Pipeline)
* 试验(A/B 测试)
* 建模

#### 产品分析
在一家消费型技术公司的一个好处是能够通过数据来观察并发现用户使用产品的特征，当用户使用产品时，我们会记录用户的特征数据来方便分析。这样的过程被成为 `logging` 或 `instrumentation`，并且这样的过程是持续不断地进行。经常会有这样的情况，我们会发现进行一项分析是比较困难的，原因在于日志中数据畸形，缺失或者不准确。由此，和工程师建立良好的关系十分必要，数据科学家能够观察到数据中的异常，帮助工程师发现bugs，反过来，工程师也会为数据科学家提供更丰富，更准确，更相关的特征，便于分析使用。

下面是我在 twitter 时进行的一些产品分析：

* 推送提醒分析：要为哪些用户推送提醒？是否跨年龄段？是否跨终端？用户打开推送的比例？
* 短消息送达率分析：如何估计跨终端的短信送达率？在发展中国家短信送达率是不是比较低？怎么改进？
* 多账号分析：为什么某些国家多账号的比率比较高呢？是什么因素促使人们去申请多个账号？

产品分析是一个迭代的过程，需要不断深化理解问题，理解商业环境，找到合适的数据集来分析问题。过不了多长时间，你就会成为数据方面的专家：什么样的数据放在哪里，该怎么使用这些数据等等。当然，这也会让你对具体的分析所需要的实践有更准确的估计。更重要的是，经过这样的过程，你会从被动变得更加主动，提出一些团队领导并没有发现的有关产品的分析。因为领导往往并不知道还有这样的数据存在，或者不知道这些数据还可以使用一些奇特的方式关联起来。

在这个过程中用到的技能：

* 打日志。分析数据，和工程师建立良好关系
* 查找和区分什么是关联数据集的能力
* 理解不同形式分析的区别，并对这些任务所需要的时间有更精确的估计
* 了解查询语言，通常使用的是 R 或者 Python

#### 数据流水线
A类数据科学家可能不会经常提交面向生产环境的代码，但通常会提交有关数据流水线的代码。

数据流水线的概念和 Unix 中管道的概念很接近，就是一组操作，依次执行，能够自动地帮我们处理数据。

数据流水线需要关注的问题包括依赖项，执行计划，资源分配，监控，错误报告和预警等环节。创建一个数据流水线的典型流程如下：

* 发现使用流水线生成数据更方便
* 基于以上需求，开始设计最终使用的数据的格式，也就是流水线数据的输出格式
* 选择一种语言，实现数据流水线
* 提交代码审查，并准备接收反馈，可能是你的代码逻辑不正确或者代码不够高效
* 测试流水线是否正常运行，结果是否符合预期
* 合并代码，部署任务，配置调度计划
* 设置监控，以接收预警或错误报告

数据流水线可能生成更便于其他人使用的结果，也便于 dashboard 展示，从中可以学习到各种最佳实践技巧。

用到的技能：

* 版本控制，通常使用 `Git`
* 进行代码审查和接收反馈的高效方式
* 如何进行测试，调试
* 依赖项管理，执行计划，资源分配，监控，错误报告和预警

#### A/B 测试
就现在，你使用的 twitter 应用很可能与我使用的并不相同，有可能你的应用具有一些我的应用并没有的特性。twitter 有大量的用户，将试验性的特征推向一小部分用户，观察他们对新特性的反应，并和控制组的用户进行比较，这就是 A/B 测试。

个人认为为大型消费技术公司工作的一个好处是，可以进行 A/B 测试。作为数据科学家，我们需要探索**因果关系**，这通常情况下都不容找到。
    
    在twitter，几乎没有一天不在进行 A/B 测试，这已经深入我们骨髓和我们的产品开发周期中。
    -- Alex Roetter, 工程方面的公司VP
    
进行一次 A/B 测试的典型步骤如下：

    收集样本 -> 分桶 -> 应用差异特性 -> 收集结果 -> 作出分析
    
    Gather Samples -> Assign Buckets -> Apply Treatments -> Measure Outcomes -> Make Comparisons

看起来挺简单的，但我认为 A/B 测试是最被低估同时也是非常有技巧的一项技能，很可惜，学校并不教这个。让我们再来看下这5个步骤：

* 收集样本--我们需要多少样本？每个桶中应该有多少用户？我们能否保证试验具有足够的说服力？
* 分桶--哪些人有资格参加测试？在哪个地方的代码代码中进行分桶，展示不同的特性？放在选定的地方会不会导致数据稀释？(比方说，参加测试的用户根本看不到试验的特性)
* 应用差异特性--有没有其它团队正在进行的竞争性试验来获取应用的状态信息？怎么处理不同试验之间的冲突，保证数据不被污染？
* 收集结果--试验的假设是什么？试验成功或者失败的特征是什么？我们能追踪到这些特征吗？怎么追踪？还需要在哪些地方添加额外的日志记录？
* 作出分析--如果我们看到用户记录急剧增长，是否因为噪音？怎么确定结果是统计显著呢？即时是统计显著，实际是否显著呢？

回答好以上问题需要有良好的统计知识。即时你已经很精心地设计试验，其它人也完全可能成为拖油瓶。产品经理可能会一早就看数据，或者挑选对他们有利的数据；工程师可能忘掉打印成功状态的信息，或者代码放在了错误的地方，导致引入新的偏差。

作为数据科学家需要帮助团队避免以上的问题，尽可能精心设计试验，把时间浪费在不正确的试验上可一点回报都没有。更糟的是，基于错误的试验结果作出错误的决策，损失更大。

需要用到的技能：

* 假设检验：统计检验，p-value，统计显著性，多重检验等
* 试验陷阱：[翘尾效应](http://wiki.mbalib.com/wiki/%E7%BF%98%E5%B0%BE%E5%BD%B1%E5%93%8D)，数据筛选，数据稀释，桶异常等

#### 预测模型和机器学习
我在 twitter 的第一任务是为邮件提醒产品添加规则，用于降低被识别为垃圾邮件的可能。我们直到邮件是召回用户的最有效方式(通过测试知道的)，所以如何平衡就很关键。

基于以上观察，我几乎是立刻就把注意力放在了触发提醒邮件上，这种邮件在交互动作发生时会爆发式地发送到用户的邮箱。作为一个新手数据科学家，我希望建立一个机器学习模型来预测邮件的`CTR`(点击率)，来证明自己的价值。说干就干，我马上利用`Pig`计算了些用户的特征，并构建了随机森林模型来预测点击率。如果一个用户长时间的点击率都比较低，那么，我们完全可以阻止这些发送给他的邮件。

唯一的问题是，我的模型是跑在本地机器上的，虽然其它人认为它有价值，但没法调用，因为它不在生产环境中。真是个教训。

一年后， 有了新的机会构建客户流失预测模型(churn prediction model) 。现在我已经知道构建数据流水线并不困难，构建一个在线机器学习模型也不麻烦。模型训练阶段在线下完成，使用python；预测阶段则每天聚合用户特征，并且让预测模型计算每个用户的客户流失预测模型得分。

没几星期，流水线就搞定了。在确认结果具有较高的预测能力后，我们把预测结果写入到内部的数据库中，这样所有人都能够方便进行查询。这也是我学到的有关生产环境机器学习模型最有用的经验。

我刻意忽略了构建机器学习模型的细节，因为已经有很多有关的讨论了。作为数据科学家，尤其是A类数据科学家，可能会面临另外的问题：他们可能有非常好的结果，但不知道怎么把结果推送到生态系统中。我的建议是找B类数据科学家进行讨论。

需要的技能：

* 问题识别能力：需要判断哪些问题能够使用机器学习模型搞定
* 机器学习和建模的基础知识：探索性数据分析，特征工程，模型选择，模型训练/验证/测试，模型评估
* 生产环境：所有关于数据流水线的知识，能够让你的结果被所有人轻松地查询。

### 最后一些思考
数据科学是激动人心的，找到产品分析的一些结论往往能让人肾上腺素飙升，构建数据流水线也能让人有极大的满足，在 A/B 测试中可以玩 “我是上帝”的游戏。总的来说，数据科学路上困难不少，但真正喜欢数据科学的人会很快陶醉其中。

### 附录
#### 数据科学和软件工程

* [Software Development Skills for Data Scientists](http://treycausey.com/software_dev_skills.html)
* [Building Analytics at 500px](https://medium.com/@samson_hu/building-analytics-at-500px-92e9a7005c83)
* [How I Became a Data Scientist Despite Having Been a Math Major](http://stiglerdiet.com/blog/2015/May/11/how-i-became-a-data-scientist/)
* [The Data Engineering Ecosystem: An interactive map](http://insightdataengineering.com/blog/The-Data-Engineering-Ecosystem-An-Interactive-Map.html)

#### A/B 测试

* [So, you need a statistically significant sample?](http://multithreaded.stitchfix.com/blog/2015/05/26/significant-sample/)
* [Experiments at Airbnb](http://nerds.airbnb.com/experiments-at-airbnb/)
* [When should A/B testing not to be trusted when making decisions](http://www.quora.com/When-should-A-B-testing-not-be-trusted-to-make-decisions/answer/Edwin-Chen-1?srid=sL8&share=1)

#### 数据科学家招聘有关

* [What it is like to be on the data science job market](http://treycausey.com/data_science_interviews.html)
* [On picking where to work](http://multithreaded.stitchfix.com/blog/2015/03/31/advice-for-data-scientists/)



